{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6757f95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DetrImageProcessor {\n",
       "   \"do_convert_annotations\": true,\n",
       "   \"do_normalize\": true,\n",
       "   \"do_pad\": true,\n",
       "   \"do_rescale\": true,\n",
       "   \"do_resize\": true,\n",
       "   \"format\": \"coco_detection\",\n",
       "   \"image_mean\": [\n",
       "     0.485,\n",
       "     0.456,\n",
       "     0.406\n",
       "   ],\n",
       "   \"image_processor_type\": \"DetrImageProcessor\",\n",
       "   \"image_std\": [\n",
       "     0.229,\n",
       "     0.224,\n",
       "     0.225\n",
       "   ],\n",
       "   \"resample\": 2,\n",
       "   \"rescale_factor\": 0.00392156862745098,\n",
       "   \"size\": {\n",
       "     \"longest_edge\": 800,\n",
       "     \"shortest_edge\": 800\n",
       "   }\n",
       " },\n",
       " TrOCRProcessor:\n",
       " - image_processor: ViTImageProcessor {\n",
       "   \"do_normalize\": true,\n",
       "   \"do_rescale\": true,\n",
       "   \"do_resize\": true,\n",
       "   \"image_mean\": [\n",
       "     0.5,\n",
       "     0.5,\n",
       "     0.5\n",
       "   ],\n",
       "   \"image_processor_type\": \"ViTImageProcessor\",\n",
       "   \"image_std\": [\n",
       "     0.5,\n",
       "     0.5,\n",
       "     0.5\n",
       "   ],\n",
       "   \"processor_class\": \"TrOCRProcessor\",\n",
       "   \"resample\": 2,\n",
       "   \"rescale_factor\": 0.00392156862745098,\n",
       "   \"size\": {\n",
       "     \"height\": 384,\n",
       "     \"width\": 384\n",
       "   }\n",
       " }\n",
       " \n",
       " - tokenizer: RobertaTokenizerFast(name_or_path='processor/microsoft/trocr-base-handwritten', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       " \t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       " \t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       " \t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       " \t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       " \t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n",
       " }\n",
       " \n",
       " {\n",
       "   \"processor_class\": \"TrOCRProcessor\"\n",
       " })"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#有了前两个模型的经验，这个部分的代码就很简单了\n",
    "#首先是加载processor，它负责送进模型的数据的格式\n",
    "import torch\n",
    "import random\n",
    "from transformers import AutoImageProcessor, TrOCRProcessor\n",
    "\n",
    "#文字定位detr-resnet-50模型的processor,\n",
    "processor_location = AutoImageProcessor.from_pretrained(\n",
    "    'processor/facebook/detr-resnet-50',\n",
    "    size={\n",
    "        'longest_edge': 800,\n",
    "        'shortest_edge': 800\n",
    "    })\n",
    "\n",
    "#文字定位trocr-base-handwritten模型的processor,\n",
    "processor_recognition = TrOCRProcessor.from_pretrained(\n",
    "    'processor/microsoft/trocr-base-handwritten')\n",
    "\n",
    "processor_location, processor_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "191fe291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载之前训练好的文字定位模型\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, pixel_values, pixel_mask):\n",
    "        last_hidden_state = self.model(pixel_values=pixel_values,\n",
    "                                       pixel_mask=pixel_mask).last_hidden_state\n",
    "\n",
    "        class_pred = self.class_labels_classifier(last_hidden_state)\n",
    "        box_pred = self.bbox_predictor(last_hidden_state).sigmoid()\n",
    "\n",
    "        return class_pred, box_pred\n",
    "\n",
    "\n",
    "model_location = torch.load('model/文字定位.model').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78b6aa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载之前训练好的文字识别模型\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, pixel_values):\n",
    "        last_hidden_state = self.encoder(pixel_values).last_hidden_state\n",
    "\n",
    "        input_ids = torch.full([len(pixel_values), 1], \n",
    "                               processor_recognition.tokenizer.cls_token_id).to('cuda')\n",
    "        for i in range(127):\n",
    "            logits = self.decoder(input_ids=input_ids, \n",
    "                                  encoder_hidden_states=last_hidden_state).logits\n",
    "            logits = logits.argmax(2)[:, -1].unsqueeze(1)\n",
    "            input_ids = torch.cat([input_ids, logits], 1)\n",
    "\n",
    "        return input_ids\n",
    "        \n",
    "model_recognition = torch.load('model/文字识别.model').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14e7661f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['image'],\n",
       "     num_rows: 500\n",
       " }),\n",
       " {'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=800x800>})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#准备数据\n",
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk('dataset/data')['train']\n",
    "dataset = dataset.select(range(500)).remove_columns(['ocr'])\n",
    "\n",
    "def f(data):\n",
    "    data['image'] = data['image'].resize([800, 800])\n",
    "    return data\n",
    "\n",
    "dataset = dataset.map(f)\n",
    "\n",
    "dataset, dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2792648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 2.文字定位Loss函数.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59851fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([6, 3, 2, 0, 1, 4, 7, 5, 2],\n",
       " [[68.11900329589844, 349.3677978515625, 520.3612060546875, 508.5596923828125],\n",
       "  [63.87397003173828, 278.0183410644531, 187.609130859375, 339.68572998046875],\n",
       "  [291.8573303222656, 167.39292907714844, 359.6639099121094, 244.5283203125],\n",
       "  [48.233367919921875,\n",
       "   82.97744750976562,\n",
       "   223.44288635253906,\n",
       "   161.0249786376953],\n",
       "  [54.67331314086914,\n",
       "   181.38064575195312,\n",
       "   122.99226379394531,\n",
       "   257.2747802734375],\n",
       "  [240.29493713378906,\n",
       "   269.9354248046875,\n",
       "   311.1112976074219,\n",
       "   329.4949035644531],\n",
       "  [226.87704467773438, 571.681884765625, 715.569091796875, 669.05029296875],\n",
       "  [348.2613220214844,\n",
       "   264.5687255859375,\n",
       "   416.0237731933594,\n",
       "   322.81536865234375],\n",
       "  [291.8280029296875,\n",
       "   167.22036743164062,\n",
       "   360.14593505859375,\n",
       "   247.28839111328125]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#文字定位裁剪函数\n",
    "def location(image):\n",
    "    #数据先进文字定位processor处理\n",
    "    data = processor_location(image, return_tensors='pt').to('cuda')\n",
    "    #冻结参数以后，数据进入文字定位模型处理\n",
    "    with torch.no_grad():\n",
    "        class_pred, box_pred = model_location(data['pixel_values'], data['pixel_mask'])\n",
    "    \n",
    "    class_pred = class_pred.argmax(dim=2)\n",
    "    box_pred = box_pred[class_pred <= 7][:16]\n",
    "    class_pred = class_pred[class_pred <= 7][:16]\n",
    "    \n",
    "    #matcher函数就是把文字定位模型detr-resnet-50输出的x（左上横坐标），y（左上纵坐标），w（宽度），h（高度），转变为四个角的坐标\n",
    "    #注意！上述的坐标都是比例坐标，宽高也是比例长度\n",
    "    box_pred = matcher.xywh_to_x1y1x2y2(box_pred)\n",
    "    #比例坐标转变为绝对值坐标\n",
    "    box_pred *= 800\n",
    "\n",
    "    return class_pred.tolist(), box_pred.tolist()\n",
    "\n",
    "image = random.choice(dataset)['image']\n",
    "\n",
    "class_pred, box_pred = location(image)\n",
    "    \n",
    "class_pred, box_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efb9017f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['澳门特别行政区澳门特别行政区', '2003', '汉', '', '男', '10', '', '27', '汉']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PIL.Image\n",
    "\n",
    "\n",
    "def recognition(image, box_pred):\n",
    "\n",
    "    def pad(image):\n",
    "        w, h = image.size\n",
    "    \n",
    "        ratio = 384 / max(w, h)\n",
    "    \n",
    "        w = int(ratio * w)\n",
    "        h = int(ratio * h)\n",
    "    \n",
    "        image = image.resize([w, h])\n",
    "    \n",
    "        pad = PIL.Image.new('RGB', [384, 384], 'black')\n",
    "        pad.paste(image, [0, 0])\n",
    "    \n",
    "        return pad\n",
    "\n",
    "    def decode(input_ids):\n",
    "        input_ids = input_ids.tolist()\n",
    "    \n",
    "        if processor_recognition.tokenizer.sep_token_id in input_ids:\n",
    "            idx = input_ids.index(processor_recognition.tokenizer.sep_token_id) + 1\n",
    "            input_ids = input_ids[:idx]\n",
    "    \n",
    "        return processor_recognition.tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "\n",
    "    image = [pad(image.crop(box)) for box in box_pred]\n",
    "    pixel_values = processor_recognition(image, return_tensors='pt').pixel_values.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model_recognition(pixel_values)\n",
    "    \n",
    "    return [decode(i) for i in logits]\n",
    "\n",
    "\n",
    "text = recognition(image, box_pred)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "961a51c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "#切断而已，可以无视\n",
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f913390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.ImageDraw\n",
    "import PIL.ImageFont\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def show(image, box_pred, class_pred):\n",
    "    font = PIL.ImageFont.truetype('arial.ttf', size=50)\n",
    "    draw = PIL.ImageDraw.Draw(image)\n",
    "    for b, c in zip(box_pred, class_pred):\n",
    "        draw.rectangle(b, outline='red', width=5)\n",
    "        draw.text(b[:2], str(c), fill='red', font=font)\n",
    "    \n",
    "    plt.figure(figsize=[3, 3])\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show(image, box_pred, class_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc84848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "姓名->邭俊苋\n",
      "性别->男\n",
      "民族->汉\n",
      "年->1998\n",
      "月->9\n",
      "日->31\n",
      "住址->重庆市西阳圈家族自治县\n",
      "号码->\n",
      "姓名->厉苉茉\n",
      "性别->女\n",
      "民族->汉\n",
      "年->2000\n",
      "月->2\n",
      "日->18\n",
      "住址->内蒙古自治区和塎河区\n",
      "号码->546253200002187064\n",
      "姓名->冉银梋\n",
      "性别->女\n",
      "民族->汉\n",
      "年->2004\n",
      "月->9\n",
      "日->17\n",
      "住址->香�港特别行政区山区\n",
      "号码->2575722004091762011\n",
      "姓名->石苉凤\n",
      "性别->男\n",
      "民族->汉\n",
      "年->2002\n",
      "月->6\n",
      "日->23\n",
      "住址->\n",
      "号码->598936200206237046\n",
      "姓名->\n",
      "性别->女\n",
      "民族->汉\n",
      "年->\n",
      "月->10\n",
      "日->4\n",
      "住址->贵州省辊萉市陔西县\n",
      "号码->615753199610404289\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    image = random.choice(dataset)['image']\n",
    "    class_pred, box_pred = location(image)\n",
    "    text = recognition(image, box_pred)\n",
    "\n",
    "    #show(image, box_pred, class_pred)\n",
    "\n",
    "    class_name = ['姓名','性别','民族','年','月','日','住址','号码']\n",
    "    for cls in range(8):\n",
    "        if cls not in class_pred:\n",
    "            continue\n",
    "        idx = class_pred.index(cls)\n",
    "        print(class_name[cls] + '->' + text[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51239a51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
